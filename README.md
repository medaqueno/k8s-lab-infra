Gu√≠a de Despliegue: Talos Linux & Kubernetes (Enfoque Enterprise)

Esta gu√≠a documenta la arquitectura, el provisionamiento y la validaci√≥n de un cl√∫ster de Kubernetes basado en Talos Linux.

El documento abarca desde la configuraci√≥n inicial explicada paso a paso en un entorno de laboratorio (Single Node) hasta la arquitectura de referencia para producci√≥n (High Availability), incluyendo estrategias de GitOps y comandos operativos esenciales.

üõ†Ô∏è Instalaci√≥n de Herramientas (CLI)

Antes de interactuar con el cl√∫ster, es necesario preparar la estaci√≥n de administraci√≥n (Management Plane). Estas herramientas nos permitir√°n hablar con la API de Talos y la API de Kubernetes.

macOS (Homebrew)

```sh
brew install siderolabs/tap/talosctl
brew install kubectl

# comprobar versi√≥n talos
talosctl version --client
```

Linux (Curl)

curl -sL [https://talos.dev/install](https://talos.dev/install) | sh
# Mueve el binario al path del sistema
sudo mv talosctl /usr/local/bin/


üè¢ Arquitectura de Referencia: Entorno de Producci√≥n

En un entorno empresarial real, la arquitectura difiere del laboratorio en disponibilidad y separaci√≥n de responsabilidades.

1. Topolog√≠a F√≠sica (Bare-Metal)

En producci√≥n, el objetivo primordial es eliminar Puntos √önicos de Fallo (SPOF).

graph TD
    subgraph "Control Plane (Quorum etcd)"
        CP1[Nodo CP 1]
        CP2[Nodo CP 2]
        CP3[Nodo CP 3]
    end

    subgraph "Data Plane (Workloads)"
        W1[Worker 1 - Zona A]
        W2[Worker 2 - Zona B]
        W3[Worker 3 - Zona C]
    end

    LB[Virtual IP / Load Balancer] --> CP1
    LB --> CP2
    LB --> CP3

    W1 -.-> LB
    W2 -.-> LB
    W3 -.-> LB


Control Plane (3 Nodos): Kubernetes requiere un n√∫mero impar de nodos maestros para mantener el qu√≥rum de la base de datos etcd. Si un nodo cae, los otros dos mantienen el cl√∫ster vivo y operativo.

Virtual IP (VIP): Se configura una IP flotante (VIP) en capa 2 (ARP) o BGP. Tanto los workers como los administradores apuntan a esta VIP, desacoplando el servicio de la IP f√≠sica de un nodo espec√≠fico.

Worker Nodos (N Nodos): Dedicados exclusivamente a ejecutar aplicaciones de negocio. Se recomienda separarlos f√≠sicamente.

Red: Se utiliza Bonding (LACP) en las interfaces de red para redundancia de cables y switches.

2. Estrategia GitOps (Multi-Repositorio)

Para escalar el desarrollo y la gobernanza, separamos la definici√≥n de la infraestructura del c√≥digo de las aplicaciones.

Repositorio

Responsabilidad

Contenido

infra-talos-fleet

Equipo Infraestructura

Configuraci√≥n del OS Talos (machineconfig), definici√≥n de nodos, configuraci√≥n de red f√≠sica y upgrades del OS.

platform-core

Equipo Platform/SRE

Componentes base del cl√∫ster: CNI (Cilium), Ingress Controller, Cert-Manager, Storage (Rook), Observabilidad.

app-backend-billing

Equipo Desarrollo A

C√≥digo fuente Python/Go + Helm Chart de la aplicaci√≥n.

app-frontend-store

Equipo Desarrollo B

C√≥digo fuente React/Nextjs + Manifiestos K8s.

üß™ Gu√≠a de Implementaci√≥n Detallada (Laboratorio / Single Node)

A continuaci√≥n se detallan los pasos para levantar el entorno de pruebas, explicando la raz√≥n t√©cnica de cada fase.

1. Detecci√≥n y Estado Inicial

Al arrancar la ISO de Talos Linux en el hardware, el sistema se detiene y muestra una pantalla de consola.

Estado: Maintenance

¬øPor qu√©? Talos es inmutable y seguro por defecto. No arranca con contrase√±as por defecto ni servicios expuestos. Se queda esperando en un bucle infinito a que un administrador le inyecte una configuraci√≥n firmada.

Acci√≥n: Mira el monitor y anota la direcci√≥n IP asignada por DHCP (ej: 192.168.1.41).

2. Generaci√≥n de la Identidad del Cl√∫ster

En tu m√°quina local (Mac/Linux), definimos qu√© es este cl√∫ster. Este comando genera los certificados de autoridad (CA), las claves de encriptaci√≥n y los ficheros YAML de configuraci√≥n.

# 'mi-cluster' es el nombre l√≥gico
# La URL es el endpoint donde la API escuchar√° peticiones
talosctl gen config mi-cluster [https://192.168.1.41:6443](https://192.168.1.41:6443)


Esto genera controlplane.yaml (para el nodo maestro), worker.yaml (para nodos futuros) y talosconfig (tu llave maestra).

3. Inyecci√≥n de Configuraci√≥n (Apply)

Ahora enviamos la configuraci√≥n al nodo que est√° en espera.

# Usamos --insecure porque el nodo usa certificados temporales en modo mantenimiento.
# Una vez reciba la config, generar√° sus propios certificados seguros.
talosctl apply-config --insecure --nodes 192.168.1.41 --file controlplane.yaml


El nodo se reiniciar√° autom√°ticamente, formatear√° el disco, instalar√° el OS en memoria y aplicar√° la configuraci√≥n de red.

4. Configuraci√≥n del Cliente Local

Para no tener que escribir la IP (--nodes) y el endpoint (--endpoints) en cada comando, los guardamos en nuestra configuraci√≥n local.

talosctl config endpoint 192.168.1.41
talosctl config node 192.168.1.41


5. Bootstrap del Cl√∫ster (El Disparo de Salida)

Aunque el nodo ya tiene configuraci√≥n, la base de datos etcd no arranca sola.

¬øPor qu√©? Para prevenir "Split-Brain". Si tuvieras 3 nodos, Talos no sabe cu√°l debe iniciar el cl√∫ster. Debemos decirle expl√≠citamente al primer nodo: "T√∫ eres el l√≠der inicial".

talosctl bootstrap


Tras este comando, Kubernetes iniciar√°. Puedes monitorizarlo con talosctl dashboard.

6. Obtenci√≥n de Acceso (Kubeconfig)

Talos gestiona sus propios certificados para la API de Kubernetes. Debemos extraerlos para usar kubectl.

talosctl kubeconfig > ~/.kube/config


7. Habilitar Cargas de Trabajo (Taint Removal)

‚ö†Ô∏è Concepto Arquitect√≥nico: Por defecto, Kubernetes protege el plano de control aplicando un Taint (NoSchedule). Esto impide que tus aplicaciones consuman CPU/RAM reservada para el sistema.

En Lab: Como solo tenemos un nodo, debemos quitar esta protecci√≥n para poder desplegar nuestras apps.

# El '-' al final indica la eliminaci√≥n de la regla
kubectl taint node <nombre-del-nodo> node-role.kubernetes.io/control-plane:NoSchedule-


üì¶ Despliegue de Aplicaciones (Validaci√≥n)

Para confirmar que la red (CNI) y el DNS funcionan, desplegamos dos servicios que se comuniquen entre s√≠.

echo-server.yaml (Backend)

Servidor Nginx simple escuchando en puerto 80.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo-server-deploy
  labels:
    app: echo-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: echo-server
  template:
    metadata:
      labels:
        app: echo-server
    spec:
      containers:
      - name: echo-server
        image: nginx:latest
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: echo-server-svc
spec:
  selector:
    app: echo-server
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP


Prueba de Conectividad

Aplicamos el servidor y lanzamos un pod cliente temporal para probar la resoluci√≥n DNS interna.

# 1. Desplegar servidor
kubectl apply -f echo-server.yaml

# 2. Validar comunicaci√≥n (DNS + HTTP)
# Creamos un pod con curl, lanzamos la petici√≥n y lo borramos (--rm) al terminar
kubectl run curl-test --image=curlimages/curl -it --rm -- curl -v echo-server-svc


√âxito: Si recibes un HTTP 200 OK, tu cl√∫ster es funcional.

‚ö° Cheatsheet: Comandos Esenciales

Resumen r√°pido para la operaci√≥n diaria y resoluci√≥n de problemas.

üêß Gesti√≥n del Nodo (Talosctl)

Acci√≥n

Comando

Descripci√≥n

Dashboard

talosctl dashboard

Panel visual en terminal con m√©tricas y logs en tiempo real.

Listar procesos

talosctl ps

Muestra procesos internos de Linux (containerd, kubelet, udevd).

Logs del sistema

talosctl logs <service>

Ej: talosctl logs kubelet o talosctl logs etcd para depurar el arranque.

Reiniciar nodo

talosctl reboot

Reinicio ordenado (drena el nodo primero si es posible).

Upgrade OS

talosctl upgrade --image <url>

Actualizaci√≥n at√≥mica del sistema operativo preservando la configuraci√≥n.

Reset

talosctl reset

Peligroso: Borra todo el disco y devuelve el nodo a estado de mantenimiento.

‚ò∏Ô∏è Gesti√≥n del Cl√∫ster (Kubectl)

Acci√≥n

Comando

Descripci√≥n

Estado Nodos

kubectl get nodes -o wide

IPs, Versi√≥n K8s, OS Image y estado (Ready/NotReady).

Todos los Pods

kubectl get pods -A

Ver pods de sistema (CoreDNS, CNI) y usuario a la vez.

Logs App

kubectl logs -f -l app=<label>

Sigue los logs de todos los pods con esa etiqueta.

Debug Pod

kubectl describe pod <nombre>

Fundamental para ver errores de ImagePullBackOff o falta de recursos.

Shell Remota

kubectl exec -it <pod> -- sh

Entrar dentro del contenedor para depurar red/archivos.

Reiniciar App

kubectl rollout restart deployment/<nombre>

Fuerza la recreaci√≥n de los pods sin borrar el deployment.